## Lessons Learned for Intelligent Lead Analyzer (ILA) Development

This document captures key lessons and recommendations based on previous development experience and the new PRD for the Intelligent Lead Analyzer, which focuses on a browser extension and AI-powered backend analysis.

**I. Backend API Development (FastAPI)**

1.  **Router Configuration & Prefixes:**
    *   **Lesson:** Incorrect prefixing in FastAPI routers can lead to 404 errors. In the previous project, `generation_router.py` initially had its own `prefix="/generation"`, which, when combined with `app.include_router(..., prefix="/api/v1/generation")` in `api_main.py`, resulted in an effective prefix of `/api/v1/generation/generation`.
    *   **Recommendation (ILA):** Define router prefixes *only* when including them in the main `FastAPI` app instance (e.g., in `api_main.py`). Keep `APIRouter` definitions in individual router files clean of prefixes unless there's a specific sub-routing need within that file.
    *   **PRD Relevance:** The ILA backend API (`POST /api/v1/analyze`, `GET /api/v1/analysis/{analysis_id}`, etc.) will require careful router setup.

2.  **Pydantic Model Validation & Error Handling:**
    *   **Lesson:** FastAPI's use of Pydantic provides automatic request validation. Understanding how to test for and interpret `422 Unprocessable Entity` errors is crucial. Specific error messages (e.g., "URL scheme should be 'http' or 'https'") are important for tests and debugging.
    *   **Recommendation (ILA):** Define clear Pydantic models for all API request and response bodies (e.g., `ScrapedProfile`, `Analysis` as per PRD). Write specific tests for validation errors, checking for expected error messages/types.
    *   **PRD Relevance:** `ProfileGenerationRequest` (from previous project) and the new PRD's `ScrapedProfile` and `Analysis` models will benefit from this.

3.  **Dependency Injection for Services:**
    *   **Lesson:** While the previous project instantiated `LinkedInScraper` globally in `generation_router.py`, for more complex applications or easier testing, FastAPI's dependency injection (`Depends`) is preferable.
    *   **Recommendation (ILA):** For services like the `AIAnalysisModule` or any data access/scraping components, use FastAPI's `Depends` system. This makes mocking in tests cleaner and promotes modularity.
    *   **PRD Relevance:** The "AI Analysis Module" and "Data Store" interactions will be prime candidates for dependency injection.

4.  **Configuration Management (`ConfigManager` vs. `settings` object):**
    *   **Lesson:** The previous project evolved from a custom `ConfigManager` to using a Pydantic `settings` object (as seen in `api_main.py` for `SESSION_SECRET_KEY`). Standardized settings management is cleaner.
    *   **Recommendation (ILA):** Fully adopt a Pydantic `Settings` model for all backend configurations (LLM API keys, database URLs, etc.) as described in the new PRD (US-009). Ensure API keys are loaded securely (e.g., from environment variables).
    *   **PRD Relevance:** Secure LLM API key configuration is a core requirement (US-009).

5.  **CORS Configuration:**
    *   **Lesson:** `CORSMiddleware` was correctly set up in `api_main.py`.
    *   **Recommendation (ILA):** Continue to use `CORSMiddleware`. The browser extension will be a different origin than the backend, making CORS essential. Ensure `allow_origins` is correctly configured for development (localhost with various ports) and production.

**II. Web Scraping (Browser Extension Focus)**

1.  **Scraping Strategy (SerpApi vs. Direct Extension Scraping):**
    *   **Lesson:** The previous project used SerpApi for LinkedIn searches, which abstracts away direct browser interaction but relies on search engine results. Selenium was present but unused for deep scraping.
    *   **New PRD Focus:** The ILA PRD heavily emphasizes the browser extension performing direct DOM scraping ("content script executes scraping logic using CSS selectors or DOM traversal").
    *   **Recommendation (ILA):**
        *   Prioritize developing robust direct scraping capabilities within the browser extension's content scripts.
        *   Research and implement resilient selector strategies (less brittle, using `id`, `data-*`, ARIA roles as suggested in PRD Risk 1).
        *   Plan for website structure changes (PRD Risk 1) and consider configurable selectors fetched from the backend (MVP+1, US-004).
        *   Be mindful of anti-scraping measures (PRD Risk 2); the extension running in user context helps but isn't foolproof.

2.  **Stubbing Scraper Functionality:**
    *   **Lesson:** Stubbing `linkedin_scraper.scrape_user_profile_details` allowed API endpoint development and testing to proceed without a fully functional scraper.
    *   **Recommendation (ILA):** For the backend, initially stub the data expected from the browser extension. For the extension, if backend analysis is not ready, simulate backend responses. This allows parallel development.

**III. AI Integration (LLM)**

1.  **API Key Management for AI Services:**
    *   **Lesson (from Taskmaster):** AI-powered tools (like Taskmaster CLI or your future backend) require API keys. Managing these keys (e.g., in `.env` for local CLI, `mcp.json` for integrated tools, or environment variables for deployed services) is critical. Missing or incorrect keys lead to failures.
    *   **Recommendation (ILA):** As per PRD (US-009), LLM API keys *must* be configured securely on the backend and *never* exposed to the browser extension. Use environment variables or a secrets management service for the backend.
    *   **PRD Relevance:** Direct PRD requirement (US-009).

2.  **Prompt Engineering & LLM Output Parsing:**
    *   **Lesson (from Taskmaster experience):** The quality and structure of prompts significantly impact LLM output. Parsing this output reliably is also key.
    *   **Recommendation (ILA):** Plan for iterative prompt engineering for the "score" and "why" paragraph generation. Design clear contracts for what the AI module expects as input (formatted scraped data) and what it outputs. Consider structured output (e.g., JSON) from the LLM if possible to simplify parsing, though the "why" paragraph is textual.
    *   **PRD Relevance:** Feature 2 (AI-powered lead scoring & explanation) and its user stories (US-005) depend on this.

**IV. Browser Extension Development**

1.  **Extension-Backend Communication:**
    *   **Lesson (from API dev):** Secure and reliable communication is key. The previous project used HTTPS for FastAPI.
    *   **Recommendation (ILA):**
        *   All communication between the extension and backend *must* use HTTPS (PRD AC-002.1).
        *   Structure data payloads as JSON (PRD AC-002.3).
        *   Implement authentication for backend API endpoints (API key for extension, or user auth later - PRD AC-002.2, US-010).
        *   Handle potential network errors and provide feedback to the user in the extension.

2.  **Content Scripts & DOM Interaction:**
    *   **Lesson (extrapolated):** Direct DOM manipulation for scraping is powerful but can be fragile.
    *   **Recommendation (ILA):** As per PRD Risk 1 mitigations:
        *   Use robust selectors.
        *   Implement comprehensive error handling within content scripts (e.g., if elements are not found).
        *   Provide clear feedback to the user if scraping fails (US-003).

3.  **Permissions & Security:**
    *   **Recommendation (ILA):** Follow PRD Risk 3 & 4 mitigations:
        *   Request minimal permissions (e.g., `activeTab` is often better than broad host permissions initially).
        *   Have a clear privacy policy.
        *   Sanitize data displayed in the extension.
        *   Implement a Content Security Policy (CSP).

**V. Testing**

1.  **API Endpoint Testing (FastAPI `TestClient`):**
    *   **Lesson:** `TestClient` is effective for testing FastAPI endpoints. Mocking dependencies (like the scraper) using `unittest.mock.patch` is essential for isolating endpoint logic.
    *   **Recommendation (ILA):** Continue robust API testing. Mock the `AIAnalysisModule` when testing API endpoints that trigger analysis. Test for successful calls, validation errors, and error handling by the AI module (US-006).

2.  **Testing Pydantic Validation Errors:**
    *   **Lesson:** Asserting specific Pydantic error messages (e.g., `any("URL scheme should be 'http' or 'https'" in error.get("msg", "") for error in response_data.get("detail", []))`) makes tests more robust.
    *   **Recommendation (ILA):** Adopt this detailed assertion style for testing request validation.

3.  **Debugging Tests:**
    *   **Lesson:** Temporarily adding `print()` statements in test code or endpoint code can be very helpful for understanding unexpected responses or errors. Remember to remove them.
    *   **Recommendation (ILA):** Don't hesitate to use debug prints during test development, but ensure they are removed before committing.

**VI. Project Management & Workflow**

1.  **Task Management (Taskmaster Experience):**
    *   **Lesson:**
        *   CLI command length can be an issue for complex prompts (e.g., for `task-master add-task` or `update-task`).
        *   Understanding the distinction between CLI (needs `.env`) and MCP server (can use `mcp.json` for env vars) for tools with AI components is important.
        *   Subtask ID addressing in the CLI could be problematic; focusing on parent tasks and detailed descriptions might be more reliable if issues persist.
    *   **Recommendation (ILA):**
        *   If using a task manager that takes prompts, be mindful of length limitations or find ways to reference detailed instructions elsewhere (e.g., "details in chat log DD/MM/YYYY HH:MM" or point to a specific section in the PRD).
        *   The ILA PRD has a "Logical dependency chain" and MVP breakdown. Use this as a basis for task creation.

2.  **Iterative Development & Stubbing:**
    *   **Lesson:** Stubbing out components (like the LinkedIn scraper) allowed progress on other parts of the system (API endpoint).
    *   **Recommendation (ILA):** Embrace iterative development. Build and test components in isolation where possible. The PRD's phased approach (MVP, Post-MVP) aligns with this. For example, the extension can be developed to send scraped data before the AI analysis is fully implemented on the backend, by having the backend initially return placeholder scores/explanations.

3.  **Version Control (Git):**
    *   **Lesson:** Terminal display issues can sometimes mask successful command execution (e.g., a long `git commit` message). `git status` and `git log` are your friends to confirm actual state.
    *   **Recommendation (ILA):** Always verify Git operations with status/log commands if the terminal output is unclear or truncated.

**VII. General Pitfalls & Advice**

1.  **Over-Engineering Early:**
    *   **Lesson (from previous project's broad scope initially):** Trying to build too many features at once can slow down progress on core functionality.
    *   **Recommendation (ILA):** The new PRD is well-scoped for an MVP focusing on the browser extension and core analysis. Stick to this MVP tightly. Features like "Configurable Scraping Logic (MVP+1)" and "User Authentication (MVP+1)" are explicitly deferred, which is good.

2.  **Error Handling and Logging:**
    *   **Lesson:** The previous `api_main.py` had good request logging and a `SQLAlchemyError` handler. `linkedin_scraper.py` also had detailed logging.
    *   **Recommendation (ILA):** Implement comprehensive logging across all components (extension, backend API, AI module). Include request IDs for tracing. Define clear error states and messages for the extension to display to the user (e.g., scraping failed, analysis failed, backend unavailable).
    *   **PRD Relevance:** US-003 (Handle Scraping Failure), US-006 (Handling AI Module Errors - Backend), AC-007.4 (pending/error states in extension).

3.  **Assumptions vs. Explicit Design:**
    *   **Lesson (general software):** Implicit assumptions can lead to rework.
    *   **Recommendation (ILA):** The new PRD is quite detailed, which is excellent. For areas like data models (`ScrapedProfile`, `Analysis`), API contracts, and the scraping targets for MVP, ensure these are clearly defined and agreed upon before deep implementation. 